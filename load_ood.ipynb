{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from datasets import load_dataset, load_from_disk\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as trn\n",
    "\n",
    "mean = [0.5, 0.5, 0.5]\n",
    "std = [0.5, 0.5, 0.5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ood_data = dset.ImageFolder(root=r'E:\\dataset\\data\\dtd\\dtd\\images',\n",
    "                            transform=trn.Compose([trn.Resize(32), trn.CenterCrop(32),\n",
    "                            trn.ToTensor(), trn.Normalize(mean, std)]))\n",
    "ood_loader = torch.utils.data.DataLoader(ood_data, batch_size=64, shuffle=True,\n",
    "                                         num_workers=0, pin_memory=True)\n",
    "\n",
    "for idx, (data, target) in enumerate(ood_loader):\n",
    "    print(data.dtype)\n",
    "    print(target.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "ood_data = dset.Places365(root=r\"E:\\dataset\\data\\Places_365\", \n",
    "                          split='val', \n",
    "                          small=True, download=False, \n",
    "                          transform=trn.Compose([trn.Resize(32), trn.CenterCrop(32),\n",
    "                        trn.ToTensor(), trn.Normalize(mean, std)]))\n",
    "ood_loader = torch.utils.data.DataLoader(ood_data, batch_size=64, shuffle=True,\n",
    "                                         num_workers=0, pin_memory=True)\n",
    "\n",
    "for idx, (data, target) in enumerate(ood_loader):\n",
    "    print(data.dtype)\n",
    "    print(target.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import svhn\n",
    "ood_data = svhn.SVHN(root=r'E:\\dataset\\data\\svhn', split=\"test\",\n",
    "                    transform=trn.Compose([trn.Resize(32), trn.ToTensor(), trn.Normalize(mean, std)]), download=False)\n",
    "ood_loader = torch.utils.data.DataLoader(ood_data, batch_size=64, shuffle=True,\n",
    "                    num_workers=2, pin_memory=True)\n",
    "for idx, (data, target) in enumerate(ood_loader):\n",
    "    print(data.dtype)\n",
    "    print(target.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import PIL.Image as Image\n",
    "class HuggingFaceDataset(Dataset):\n",
    "    def __init__(self, hf_dataset, transforms):\n",
    "        self.dataset = hf_dataset\n",
    "        self.transform = transforms\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        # print(item.items())\n",
    "        # 转换PIL图像为张量\n",
    "        if isinstance(item['image'], Image.Image):\n",
    "            item['image'] = self.transform(item['image'])\n",
    "        return item['image'], 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_data = load_from_disk(r'E:\\dataset\\data\\lsun_c-ood\\train')\n",
    "ood_data = HuggingFaceDataset(ood_data, trn.Compose([trn.Resize(32), trn.ToTensor(), trn.Normalize(mean, std)]))\n",
    "ood_loader = torch.utils.data.DataLoader(ood_data, batch_size=64, shuffle=True,\n",
    "                    num_workers=0)\n",
    "# print(ood_data[0])\n",
    "# print(ood_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "for idx, (data, target) in enumerate(ood_loader):\n",
    "    print(data.dtype)\n",
    "    print(target.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "ood_data = load_from_disk(r'E:\\dataset\\data\\lsun_r-ood\\train')\n",
    "ood_data = HuggingFaceDataset(ood_data, trn.Compose([trn.Resize(32), trn.ToTensor(), trn.Normalize(mean, std)]))\n",
    "ood_loader = torch.utils.data.DataLoader(ood_data, batch_size=64, shuffle=True,\n",
    "                    num_workers=0)\n",
    "\n",
    "for idx, (data, target) in enumerate(ood_loader):\n",
    "    print(data.dtype)\n",
    "    print(target.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "ood_data = load_from_disk(r'E:\\dataset\\data\\isun-ood\\train')\n",
    "ood_data = HuggingFaceDataset(ood_data, trn.Compose([trn.Resize(32), trn.ToTensor(), trn.Normalize(mean, std)]))\n",
    "ood_loader = torch.utils.data.DataLoader(ood_data, batch_size=64, shuffle=True,\n",
    "                    num_workers=0)\n",
    "\n",
    "for idx, (data, target) in enumerate(ood_loader):\n",
    "    print(data.dtype)\n",
    "    print(target.dtype)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
